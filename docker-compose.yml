services:
  backend:
    ports:
      - 5000:5000
    container_name: backend
    build:
      context: src/backend
      dockerfile: ./Dockerfile

  data-notifier:
    ports:
      - 8083:8083
    container_name: data-notifier
    build:
      context: src/data-notifier
      dockerfile: ./Dockerfile
    depends_on:
      - kafka

  data-collector:
    ports:
      - 8082:8082
    container_name: data-collector
    build:
      context: src/data-collector
      dockerfile: ./Dockerfile
    depends_on:
      - kafka
      - data-notifier

  redis:
    image: bitnami/redis
    ports:
      - 6379:6379
    environment:
      - REDIS_DATABASE=urban-waste
      - ALLOW_EMPTY_PASSWORD=yes
    volumes:
      - ./data/redis:/data

  mongo:
    image: mongo
    container_name: mongodb
    ports:
      - 27017:27017
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: password
    volumes:
      - ./data/mongo:/data

  mongo-express:
    image: mongo-express
    container_name: mongo-express
    ports:
      - 8081:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: password
      ME_CONFIG_MONGODB_URL: mongodb://root:password@mongo:27017/
      ME_CONFIG_BASICAUTH: false

  postgres:
    image: postgres
    container_name: postgres
    ports:
      - 5432:5432
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: db_waste
    volumes:
      - ./data/postgres:/data

  kafka:
    image: bitnami/kafka:latest
    container_name: kafka
    ports:
      - "9092:9092" # external
      - "29092:29092" # internal
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_LISTENERS=PLAINTEXT://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,EXTERNAL://kafka:9092
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@localhost:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_CFG_LOG_DIRS=/bitnami/kafka/data
    healthcheck:
      test:
        ["CMD-SHELL", "kafka-topics.sh --bootstrap-server kafka:9092 --list"]
      interval: 5s
      timeout: 10s
      retries: 5

  kafka-ui:
    image: obsidiandynamics/kafdrop:latest
    container_name: kafdrop
    ports:
      - "9000:9000"
    environment:
      - KAFKA_BROKERCONNECT=kafka:9092
      - JVM_OPTS=-Xms32M -Xmx64M
    depends_on:
      - kafka

  spark-master:
    build:
      context: src/spark
      dockerfile: ./Dockerfile
    container_name: spark-master
    command: /bin/bash -c "chmod +x /run.sh && bin/spark-class org.apache.spark.deploy.master.Master"
    #command: bin/spark-class org.apache.spark.deploy.master.Master
    #user: root
    ports:
      - "9090:8080"
      - "7077:7077"
    volumes: #questo serve per montare il file run.sh per avere le autorizzazioni necessarie
      - ./run.sh:/run.sh
      #- ./mongo-spark-connector_2.13-10.1.1.jar:/opt/bitnami/spark/jars/mongo-spark-connector_2.13-10.1.1.jar

  spark-worker-1:
    build:
      context: src/spark
      dockerfile: ./DockerfileMongo
    container_name: spark-worker-1
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      SPARK_MODE: worker
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 2g
      SPARK_MASTER_URL: spark://spark-master:7077
  